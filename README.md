<div align="center">

# ğŸ’¡ IOTA Techbologies : Regulation AI

**SAMA/NORA Compliance Assistant**

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Next.js](https://img.shields.io/badge/Next.js-14-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Supabase](https://img.shields.io/badge/Supabase-PostgreSQL-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)](https://supabase.com/)
[![Qwen](https://img.shields.io/badge/Qwen-1.8B-FF6B6B?style=for-the-badge&logo=huggingface&logoColor=white)](https://huggingface.co/Qwen)

[![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)](LICENSE)
[![Live Demo](https://img.shields.io/badge/Live_Demo-RegTech-FF6B6B?style=for-the-badge)](https://regtech.iotatechnologies.io)
[![Status](https://img.shields.io/badge/Status-Production-brightgreen?style=for-the-badge)](https://regtech.iotatechnologies.io)

---

**LLM-Powered Regulatory Compliance Q&A System**

IOTA v2 is an intelligent compliance assistant designed specifically for SAMA (Saudi Arabian Monetary Authority) and NORA regulatory documents. Built on a RAG (Retrieval-Augmented Generation) architecture, it provides accurate, citation-backed answers with strict domain containment to ensure compliance-grade responses.

ğŸŒ **Live Demo**: [https://regtech.iotatechnologies.io](https://regtech.iotatechnologies.io)

| English | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](#) |

</div>

---

## ğŸ“Œ Overview

IOTA v2 combines advanced document understanding, semantic retrieval, and controlled LLM generation to deliver precise regulatory compliance assistance. The system enforces strict containment at multiple levels, ensuring answers are **only** derived from authorized SAMA/NORA documents with full page-level traceability.

### Key Characteristics

- âœ… **Domain-Contained**: Answers ONLY from SAMA/NORA documents
- âœ… **Page-Traceable**: Every answer includes document name and page citations
- âœ… **Deterministic**: Identical queries produce identical results
- âœ… **Multilingual**: Supports Arabic and English
- âœ… **Streaming Responses**: Real-time answer generation
- âœ… **Production-Ready**: Optimized for performance and scalability

---

## âœ¨ Key Features

### ğŸ¤– Intelligent Q&A

- **Streaming Responses**: Real-time answer generation with incremental text updates
- **Citation System**: Automatic source attribution with document names and page numbers (Page X or Pages Xâ€“Y)
- **Citation Validation**: Verifies that cited page numbers exist in retrieved chunks
- **Context-Aware**: Multi-turn conversations with conversation history (configurable max messages/chars)
- **Domain Gate**: Automatic rejection of non-regulatory queries (keyword-based filtering)
- **Intent-Based Generation**: Specialized prompts and processing for different query types
- **Extractive Builder**: For fact_definition/metadata queries, extracts direct answers from chunks
- **Semantic Grounding**: Post-generation similarity checks to ensure answers are grounded in context
- **Confabulation Detection**: Blocklist system to detect and remove ungrounded terms
- **Entity Containment Check**: Ensures fact_definition/metadata answers contain query entities
- **Answer Language Validation**: Ensures Arabic queries receive Arabic answers (with translation fallback)
- **Definition Guard**: Special handling for "what is X?" queries to prevent hallucination
- **Post-Generation Similarity Check**: Validates answer similarity to retrieved chunks
- **Translation Support**: Optional translation for Arabic queries to improve retrieval

### ğŸ“š Document Processing

- **PDF Parsing**: Advanced PDF extraction with PyMuPDF
- **OCR Support**: Image-based document processing with PaddleOCR (en + ar, 200 DPI)
- **Multilingual Extraction**: Handles Arabic and English content
- **Structured Chunking**: Intelligent document segmentation (500 tokens, 120 overlap)
- **Header/Footer Removal**: Automatic detection and removal of repeated headers/footers
- **Sentence Boundary Preservation**: Smart chunking that respects sentence endings

### ğŸ” Advanced Semantic Retrieval

- **Vector Search**: pgvector-based similarity search with configurable embeddings
  - **Local Model (Default)**: SentenceTransformer with multilingual-e5-small (384-dim) - runs locally on CPU/GPU
  - **Azure OpenAI (Optional)**: text-embedding-3-small (1536-dim) or text-embedding-3-large (3072-dim) - requires API key
- **Intent Classification**: Automatic query intent detection (fact_definition, metadata, procedural, synthesis, other)
- **Intent-Aware Retrieval**: Different top-k values per intent type (synthesis uses more chunks)
- **Dual Retrieval for Arabic**: Arabic queries trigger both Arabic and English embeddings, merged with RRF
- **Second-Pass Retrieval**: When similarity is borderline, automatically re-fetches with larger k
- **Dynamic Top-K**: Adjusts retrieval depth based on similarity scores
- **RRF Merging**: Reciprocal Rank Fusion to combine results from multiple queries
- **Reranking**: Cross-encoder reranking with keyword boosting and definition section prioritization
- **Ontology-Based Selection**: Preferred document selection based on keyword matching
- **Query Normalization**: Acronym expansion (SAMA â†’ "Saudi Arabian Monetary Authority"), legal term mapping
- **Multiple Similarity Thresholds**: Different thresholds per intent (synthesis, procedural, fact_definition, metadata)
- **Strict Quality Gates**: Additional validation layers for fact_definition and metadata queries

### ğŸ” Authentication & Security

- **WebAuthn Support**: Fingerprint-based authentication for secure access
- **Prompt Limits**: Rate limiting for unauthenticated users (10 prompts/day)
- **Session Management**: Persistent chat sessions with user tracking
- **CORS Protection**: Configurable origin whitelisting

### ğŸ’¬ Chat Interface

- **Modern UI**: Beautiful, responsive chat interface built with Next.js
- **Chat History**: Persistent conversation history with local storage
- **Source Preview**: Interactive source panel showing retrieved document snippets
- **Markdown Rendering**: Rich text formatting for answers
- **Mobile Responsive**: Optimized for desktop and mobile devices

### âš¡ Performance Optimizations

- **Efficient Storage**: Optimized chat history management
- **Lightweight Rendering**: Smart markdown rendering for large responses
- **Streaming Architecture**: Non-blocking response streaming
- **Memory Management**: Capped message history to prevent performance degradation

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Frontend Layer                               â”‚
â”‚  Next.js 14 + React 18 + Tailwind CSS + TypeScript                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Chat Interface â”‚ Authentication â”‚ Chat History â”‚ Sources     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ HTTP/REST API (FastAPI)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Backend Layer                                â”‚
â”‚  FastAPI + Python 3.10+                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Query Processing Pipeline                                    â”‚   â”‚
â”‚  â”‚  1. Domain Gate (Keyword Filter)                             â”‚   â”‚
â”‚  â”‚  2. Query Normalization (Acronym Expansion)                  â”‚   â”‚
â”‚  â”‚  3. Intent Classification (5 Types)                         â”‚   â”‚
â”‚  â”‚  4. Embedding Generation (Local Model)                      â”‚   â”‚
â”‚  â”‚  5. Vector Search (Supabase pgvector)                        â”‚   â”‚
â”‚  â”‚  6. Second-Pass Retrieval (if needed)                       â”‚   â”‚
â”‚  â”‚  7. Reranking (Cross-Encoder + Keyword Boost)              â”‚   â”‚
â”‚  â”‚  8. Context Assembly                                         â”‚   â”‚
â”‚  â”‚  9. LLM Generation (Qwen 1.8B Local) OR Extractive Builder  â”‚   â”‚
â”‚  â”‚  10. Post-Generation Validation (Grounding, Citations)       â”‚   â”‚
â”‚  â”‚  11. Streaming Response (SSE)                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Supabase   â”‚  â”‚ Local Models   â”‚  â”‚  Optional   â”‚
    â”‚ PostgreSQL  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  Azure/     â”‚
    â”‚ + pgvector  â”‚  â”‚ â”‚Sentence   â”‚ â”‚  â”‚  OpenAI     â”‚
    â”‚             â”‚  â”‚ â”‚Transformer â”‚ â”‚  â”‚  (for      â”‚
    â”‚ - Chunks    â”‚  â”‚ â”‚(Embeddings)â”‚ â”‚  â”‚  translationâ”‚
    â”‚ - Vectors   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  only)      â”‚
    â”‚ - Sessions  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ - Feedback  â”‚  â”‚ â”‚Qwen 1.8B   â”‚ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚(Generation)â”‚ â”‚
                     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### System Components

1. **Document Ingestion**: PDF processing, OCR, chunking pipeline (500 tokens, 120 overlap)
2. **Embedding Generation**: 
   - **Local Model (Default)**: SentenceTransformer with multilingual-e5-small (384-dim) - runs locally
   - **Azure OpenAI (Optional)**: text-embedding-3-small (1536-dim) or text-embedding-3-large (3072-dim) - requires API key
3. **Vector Storage**: Supabase PostgreSQL with pgvector extension
4. **Query Processing Pipeline**:
   - Domain gate (keyword filtering)
   - Query normalization (acronym expansion, legal terms)
   - Intent classification (5 types)
   - Vector search (with optional dual retrieval for Arabic)
   - Second-pass retrieval (if similarity borderline)
   - Reranking (cross-encoder + keyword boosting)
   - Context assembly
   - LLM generation (Qwen 1.8B 4-bit) OR extractive builder
   - Post-generation validation (grounding, confabulation, citations)
   - Answer language validation
5. **Response Streaming**: Incremental text delivery to frontend via SSE
6. **Session Management**: User and conversation tracking with Supabase
7. **Feedback System**: Star ratings (1-5) with optional comments

---

## ğŸ¯ Use Cases

| Scenario                        | Application                                   | Core Value                                               |
| ------------------------------- | --------------------------------------------- | -------------------------------------------------------- |
| **Regulatory Compliance** | SAMA/NORA rulebook Q&A, policy interpretation | Accurate, cited answers for compliance teams             |
| **Legal Research**        | Regulatory document search, clause retrieval  | Fast access to relevant regulations with page references |
| **Training & Onboarding** | Staff training on regulatory requirements     | Interactive learning with source-backed explanations     |
| **Audit Support**         | Document verification, citation checking      | Traceable answers for audit documentation                |
| **Multilingual Support**  | Arabic/English regulatory queries             | Seamless language switching for diverse teams            |

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** 18+ and npm
- **Python** 3.10+
- **PostgreSQL** (via Supabase with pgvector extension)
- **GPU** (required for local Qwen inference, ~6GB VRAM for 4-bit quantized model)
- **CUDA** (for GPU acceleration)
- **HuggingFace Token** (optional, for gated models like Qwen)
- **Azure OpenAI API key** (optional, only if using Azure embeddings instead of local model)
- **OpenAI API key** (optional, only if using Arabic translation feature)

### Installation

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-org/Iotav2.git
cd Iotav2
```

#### 2ï¸âƒ£ Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your credentials:
# - SUPABASE_URL (required)
# - SUPABASE_SERVICE_ROLE_KEY (required)
# - CORS_ORIGINS (required)
# - USE_MULTILINGUAL_EMBEDDING=true (default, uses local SentenceTransformer)
# - AZURE_OPENAI_API_KEY (optional, only if USE_MULTILINGUAL_EMBEDDING=false)
# - AZURE_OPENAI_ENDPOINT (optional, only if using Azure embeddings)
# - OPENAI_API_KEY (optional, only if using Arabic translation)
```

#### 3ï¸âƒ£ Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Configure environment variables
cp .env.example .env.local
# Edit .env.local:
# NEXT_PUBLIC_API_URL=http://localhost:8000
```

#### 4ï¸âƒ£ Start Services

**Backend** (Terminal 1):

```bash
cd backend
source venv/bin/activate
uvicorn server:app --host 0.0.0.0 --port 8000 --reload
```

**Frontend** (Terminal 2):

```bash
cd frontend
npm run dev
```

#### 5ï¸âƒ£ Access the Application

- **Web UI**: [http://localhost:3000](http://localhost:3000)
- **API Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“˜ API Reference

### Endpoints

#### `POST /api/user`

Create a new user session.

**Response:**

```json
{
  "user_id": "uuid-string"
}
```

#### `POST /api/query-stream`

Streaming query endpoint for real-time responses.

**Request:**

```json
{
  "query": "What are the capital requirements for banks?",
  "user_id": "optional-uuid",
  "session_id": "optional-uuid"
}
```

**Response:** Server-Sent Events (SSE) stream with JSON lines:

```json
{"type": "chunk", "text": "According to SAMA regulations..."}
{"type": "chunk", "text": " the minimum capital requirement..."}
{"type": "meta", "meta": {
  "sources": [
    {
      "document_name": "SAMA Banking Regulations",
      "page_start": 45,
      "page_end": 47,
      "snippet": "...",
      "article_id": "Article 12"
    }
  ],
  "session_id": "uuid",
  "message_id": "uuid",
  "user_id": "uuid"
}}
{"type": "done"}
```

#### `POST /api/query`

Non-streaming query endpoint (returns complete response).

**Request:** Same as `/api/query-stream`

**Response:**

```json
{
  "answer": "According to SAMA regulations...",
  "sources": [...],
  "message_id": "uuid",
  "user_id": "uuid",
  "session_id": "uuid"
}
```

#### `POST /api/feedback`

Submit feedback for a response (star rating 1-5 with optional comments).

**Request:**

```json
{
  "session_id": "uuid",
  "user_id": "uuid",
  "message_id": "uuid",
  "feedback": 5,
  "comments": "Very helpful answer"
}
```

#### `POST /api/session`

Create a new chat session for a user.

**Request:**

```json
{
  "user_id": "uuid"
}
```

**Response:**

```json
{
  "session_id": "uuid"
}
```

#### `GET /health`

Health check endpoint.

**Response:**

```json
{
  "status": "ok"
}
```

### Authentication

The API supports optional user authentication via WebAuthn. Unauthenticated users are limited to 10 prompts per day.

---

## ğŸ”§ Configuration

### Backend Environment Variables

```env
# Embeddings: Local model (default) - runs locally, no API key needed
USE_MULTILINGUAL_EMBEDDING=true  # Default: true (uses local SentenceTransformer)
MULTILINGUAL_EMBEDDING_MODEL=intfloat/multilingual-e5-small
MULTILINGUAL_EMBEDDING_DIMENSION=384

# OR use Azure OpenAI embeddings (set USE_MULTILINGUAL_EMBEDDING=false)
# USE_MULTILINGUAL_EMBEDDING=false
# AZURE_OPENAI_API_KEY=your-key
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com
# AZURE_EMBEDDING_MODEL=text-embedding-3-small  # or text-embedding-3-large
# AZURE_EMBEDDING_DIMENSION=1536  # or 3072 for large

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-key

# CORS
CORS_ORIGINS=http://localhost:3000,https://your-domain.com

# Optional: OpenAI API (for Arabic translation)
OPENAI_API_KEY=your-openai-key

# Qwen Model (default: Qwen/Qwen1.5-1.8B-Chat)
QWEN_MODEL=Qwen/Qwen1.5-1.8B-Chat

# HuggingFace Token (for gated models)
HF_TOKEN=your-hf-token
```

### Frontend Environment Variables

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ğŸ¨ Interface Showcase

### Chat Interface

- **Streaming Responses**: Real-time answer generation with typing indicators
- **Source Citations**: Clickable source references with page numbers
- **Chat History**: Persistent conversation history in sidebar
- **Markdown Support**: Rich text formatting for answers

### Authentication

- **WebAuthn Login**: Fingerprint-based secure authentication
- **Prompt Counter**: Visual indicator of remaining prompts
- **Session Management**: Automatic session creation and tracking

### Source Panel

- **Document Preview**: View retrieved document snippets
- **Page References**: Direct links to source pages
- **Highlighting**: Highlighted relevant text in sources

---

## ğŸ§© Feature Matrix

| Feature                       | Status | Description                              |
| ----------------------------- | ------ | ---------------------------------------- |
| **Streaming Responses** | âœ…     | Real-time incremental text delivery      |
| **Source Citations**    | âœ…     | Document name and page number references |
| **Chat History**        | âœ…     | Persistent conversation storage          |
| **WebAuthn Auth**       | âœ…     | Fingerprint-based authentication         |
| **Prompt Limits**       | âœ…     | Rate limiting for unauthenticated users  |
| **Multilingual**        | âœ…     | Arabic and English support with dual retrieval |
| **Domain Gate**         | âœ…     | Automatic query filtering                |
| **Intent Classification** | âœ…   | 5 intent types (fact_definition, metadata, procedural, synthesis, other) |
| **Vector Search**       | âœ…     | Semantic similarity retrieval            |
| **Reranking**          | âœ…     | Cross-encoder reranking with keyword boosting |
| **Second-Pass Retrieval** | âœ…  | Automatic re-fetch with larger k when similarity borderline |
| **RRF Merging**        | âœ…     | Reciprocal Rank Fusion for multi-query results |
| **Query Normalization** | âœ…    | Acronym expansion, legal term mapping |
| **Extractive Builder** | âœ…     | Direct extraction for fact_definition/metadata |
| **Semantic Grounding**  | âœ…     | Post-generation similarity validation |
| **Confabulation Detection** | âœ…  | Blocklist-based ungrounded term detection |
| **Citation Validation** | âœ…    | Verifies cited pages exist in chunks |
| **Answer Language Validation** | âœ… | Ensures Arabic queries get Arabic answers |
| **PDF Processing**      | âœ…     | PyMuPDF-based extraction                 |
| **OCR Support**         | âœ…     | PaddleOCR image processing (en + ar)    |
| **Markdown Rendering**  | âœ…     | Rich text formatting (limited for large responses) |
| **Mobile Responsive**   | âœ…     | Optimized mobile interface               |
| **Conversation History** | âœ…    | Configurable max messages/chars per session |
| **Feedback System**    | âœ…     | Star ratings (1-5) with optional comments |

---

## ğŸ”’ Security & Compliance

### Containment Strategy

The system enforces strict domain containment at multiple levels:

1. **Domain Gate**: Rule-based keyword filtering (SAMA, NORA, regulatory terms in EN + AR)
2. **Intent Classification**: Query type detection for specialized processing
3. **Similarity Thresholds**: Intent-specific thresholds (synthesis, procedural, fact_definition, metadata)
4. **Strict Quality Gates**: Additional validation for fact_definition/metadata queries
5. **Generation Prompt**: Strict context-only answer generation with mandatory citations
6. **Semantic Grounding**: Post-generation similarity checks
7. **Confabulation Detection**: Blocklist terms that appear in answer but not context
8. **Entity Containment**: Ensures fact_definition/metadata answers contain query entities
9. **Citation Validation**: Verifies cited pages exist in retrieved chunks
10. **Definition Guard**: Prevents hallucination for "what is X?" queries

### Security Features

- âœ… **CORS Protection**: Configurable origin whitelisting
- âœ… **API Authentication**: Optional WebAuthn-based user authentication
- âœ… **Rate Limiting**: Prompt limits for unauthenticated access
- âœ… **Input Validation**: Strict query validation and sanitization
- âœ… **Error Handling**: Safe error messages without internal details

---

## âš¡ Performance Optimizations

### Frontend Optimizations

- **Efficient Storage**: Optimized chat history management (max 50 chats, max 50 rendered messages)
- **Lightweight Rendering**: Smart markdown rendering (disabled for responses >1000 chars)
- **Memoization**: React.useMemo for sorted chat lists, React.memo for expensive components
- **Fixed Height Input**: Textarea with fixed height to prevent layout shifts
- **Narrowed Transitions**: Only color/shadow transitions, not layout-affecting properties
- **Disabled Highlighting**: Snippet highlighting disabled for performance (O(nÂ²) algorithm)
- **Message Capping**: Only renders latest 50 messages to limit DOM work

### Backend Optimizations

- **Streaming Architecture**: Non-blocking response streaming via threading and queue
- **Connection Pooling**: Efficient database connection management via Supabase client
- **Model Caching**: Qwen model loaded once and reused (persistent in memory)
- **Quantization**: 4-bit NF4 quantization reduces VRAM usage (~6GB for 1.8B model)
- **Intent-Aware Processing**: Different retrieval strategies per query type
- **Early Rejection**: Domain gate prevents unnecessary API calls
- **Batch Processing**: Efficient chunk insertion to Supabase

---

## ğŸ› ï¸ Development

### Project Structure

```
Iotav2/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ server.py               # Main API server (FastAPI routes)
â”‚   â”œâ”€â”€ simple_rag.py          # Core RAG pipeline (retrieval, generation, validation)
â”‚   â”œâ”€â”€ qwen_model.py          # Qwen 1.8B LLM inference (4-bit quantized)
â”‚   â”œâ”€â”€ embeddings.py          # Embedding generation (Azure OpenAI or multilingual)
â”‚   â”œâ”€â”€ rerank.py              # Cross-encoder reranking with keyword boosting
â”‚   â”œâ”€â”€ query_multilingual.py  # Arabic detection, dual retrieval, RRF merging
â”‚   â”œâ”€â”€ query_normalize.py     # Query normalization (acronym expansion, legal terms)
â”‚   â”œâ”€â”€ extractive_builder.py  # Direct extraction for fact_definition/metadata
â”‚   â”œâ”€â”€ grounding.py           # Semantic grounding validation
â”‚   â”œâ”€â”€ ontology.py            # Ontology-based document selection
â”‚   â”œâ”€â”€ translate.py           # Arabic translation support
â”‚   â”œâ”€â”€ users_sessions.py      # User, session, message, feedback management
â”‚   â”œâ”€â”€ supabase_client.py     # Supabase client wrapper
â”‚   â”œâ”€â”€ config.py              # Configuration (thresholds, flags, paths)
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/                   # Next.js frontend
â”‚   â”œâ”€â”€ app/                   # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ page.tsx           # Main chat page
â”‚   â”‚   â””â”€â”€ api/               # API routes (if any)
â”‚   â”œâ”€â”€ components/            # React components
â”‚   â”‚   â”œâ”€â”€ chat/              # Chat interface components
â”‚   â”‚   â”œâ”€â”€ sidebar/           # Chat history sidebar
â”‚   â”‚   â””â”€â”€ ui/                # shadcn/ui components
â”‚   â”œâ”€â”€ lib/                   # Utilities and types
â”‚   â”‚   â”œâ”€â”€ types.ts           # TypeScript interfaces
â”‚   â”‚   â”œâ”€â”€ storage.ts         # localStorage utilities
â”‚   â”‚   â””â”€â”€ utils.ts           # Helper functions
â”‚   â”œâ”€â”€ hooks/                 # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useFingerprintAuth.ts  # WebAuthn authentication
â”‚   â”‚   â””â”€â”€ usePromptLimit.ts      # Prompt limit tracking
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ Core/                      # Architecture documentation
â”‚   â””â”€â”€ 01_overall_architecture.md
â””â”€â”€ README.md
```

### Development Mode

**Backend** (with hot reload):

```bash
cd backend
source venv/bin/activate
uvicorn server:app --reload
```

**Frontend** (with hot reload):

```bash
cd frontend
npm run dev
```

---

## ğŸ“Š Technology Stack

### Frontend

- **Framework**: Next.js 14 (App Router)
- **UI Library**: React 18
- **Styling**: Tailwind CSS
- **Components**: Radix UI, shadcn/ui
- **Animations**: Framer Motion
- **Markdown**: react-markdown + remark-gfm
- **Authentication**: @simplewebauthn/browser

### Backend

- **Framework**: FastAPI
- **Language**: Python 3.10+
- **LLM**: Qwen 1.8B Instruct (4-bit quantized with BitsAndBytes)
- **Embeddings**: 
  - **Local Model (Default)**: SentenceTransformer with multilingual-e5-small (384-dim) - runs locally
  - **Azure OpenAI (Optional)**: text-embedding-3-small (1536-dim) or text-embedding-3-large (3072-dim) - requires API key
- **Database**: Supabase (PostgreSQL + pgvector)
- **PDF Processing**: PyMuPDF (fitz)
- **OCR**: PaddleOCR (en + ar, 200 DPI)
- **Vector Search**: pgvector (cosine similarity)
- **Reranking**: Cross-encoder reranking with keyword boosting

---

---

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **SAMA** (Saudi Arabian Monetary Authority) for regulatory framework
- **Supabase** for database infrastructure
- **Qwen** team for the open-source LLM

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-org/Iotav2/issues)

---

<div align="center">

**Built with â¤ï¸ by IOTA Technologies**

[â­ Star us on GitHub](https://github.com/your-org/Iotav2) | [ğŸ› Report Bug](https://github.com/your-org/Iotav2/issues)

</div>
